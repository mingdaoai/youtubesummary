{"transcript": "Metarprompting is turning out to be a\nvery very powerful tool that everyone's\nusing now. It kind of actually feels\nlike coding in you know 1995 like the\ntools are not all the way there. We're\nyou know in this new frontier. But\npersonally it also kind of feels like\nlearning how to manage a person where\nit's like how do I actually communicate\nuh you know the things that they need to\nknow in order to make a good decision.\n[Music]\nWelcome back to another episode of the\nlight cone. Today we're pulling back the\ncurtain on what is actually happening\ninside the best AI startups when it\ncomes to prompt engineering. We surveyed\nmore than a dozen companies and got\ntheir take right from the frontier of\nbuilding this stuff, the practical tips.\nJared, why don't we start with an\nexample from one of your best AI\nstartups? I managed to get an example\nfrom a company called Parahelp. Parahelp\ndoes AI customer support. There are a\nbunch of companies who who are doing\nthis, but Parhel is doing it really\nreally well. They're actually powering\nthe customer support for Perplexity and\nReplet and Bolt and a bunch of other\nlike top AI companies now. So, if you if\nyou go and you like email a customer\nsupport ticket into Perplexity, what's\nactually responding is like their AI\nagent. The cool thing is that the\nPowerhel guys very graciously agreed to\nshow us the actual prompt that is\npowering this agent um and to put it on\nscreen on YouTube for the entire world\nto see. Um it's like relatively hard to\nget these prompts for vertical AI agents\nbecause they're kind of like the crown\njewels of the IP of these companies and\nso very grateful to the Powerhel guys\nfor agreeing to basically like open\nsource this prompt. Diana, can you walk\nus through this very detailed prompt?\nIt's super interesting and it's very\nrare to get a chance to see this in\naction. So the interesting thing about\nthis prompt is actually first it's\nreally long. It's very detailed in this\ndocument you can see is like six pages\nlong just scrolling through it. The big\nthing that a lot of the best prompts\nstart with is this concept of uh setting\nup the role of the LLM. You're a manager\nof a customer service agent and it\nbreaks down into bullet points what it\nneeds to do. Then the big thing is\ntelling the the task which is to approve\nor reject a tool call because it's\norchestrating agent calls from all these\nother ones. And then it gives it a bit\nof the highle plan. It breaks it down\nstep by step. You see steps one, two,\nthree, four, five. And then it gives\nsome of the important things to keep in\nmind that it should not kind of go weird\ninto calling different kinds of tools.\nIt tells them how to structure the\noutput because a lot of things with\nagents is you need them to integrate\nwith other agents. So almost like gluing\nthe API call. So the is important to\nspecify that it's going to give certain\nuh output of accepting or rejecting and\nin this format. Then this is sort of the\nhighle section and one thing that the\nbest prompts do they break it down sort\nof in this markdown type of style uh\nformatting. So you have sort of the\nheading here and then later on it goes\ninto more details on how to do the\nplanning and you see this is like a sub\nbullet part of it and as part of the\nplan there's actually three big sections\nis how to plan and then how to create\neach of the steps in the plan and then\nthe highle example of the plan. One big\nthing about the best prompts is they\noutline how to reason about the task and\nthen a big thing is giving it giving it\nan example and this is what it does. And\none thing that's interesting about this\nit it looks more like programming than\nwriting English because it has this uh\nXML tag kind of format to specify sort\nof the plan. We found that it makes it a\nlot easier for LMS to follow because a\nlot of LMS were post-trained in LHF with\nkind of XML type of input and it turns\nout to produce better results. Yeah. One\nthing I'm surprised that isn't in here\nor maybe this is just the version that\nthey released. What I almost expect is\nthere to be a section where it describes\na particular scenario and uh actually\ngives example output for that scenario.\nThat's in like the next stage of the\npipeline. Yeah. Oh, really? Okay. Yeah.\nBecause it's customer specific, right?\nBecause like every customer has their\nown like flavor of how to respond to\nthese support tickets. And so their\nchallenge like a lot of these agent\ncompanies is like how do you build a\ngeneral purpose product when every\ncustomer like wants you know has like\nslightly different workflows and like\npreferences. has a really interesting\nthing that I see the vertical AI agent\ncompanies talking about a lot which is\nlike how do you have enough flexibility\nto make special purpose logic without\nturning into a consulting company where\nyou're building like a new prompt for\nfor for every customer. I actually think\nthis like concept of like forking and\nmerging prompts across customers and\nwhich part of the prompt is customer\nspecific versus like companywide is like\na like a really interesting thing that\nthe world is only just beginning to\nexplore. Yeah, that's a very good point\nJared. So this is concept of uh defining\nthe prompt in the system prompt. Then\nthere's a de developer prompt and then\nthere's a user prompt. So what this mean\nis uh the system prompt is basically\nalmost like defining uh sort of the\nhighle API of how your company operates.\nIn this case the example of parhel is\nvery much a system prompt. There's\nnothing specific about the customer. And\nthen as they add specific instances of\nthat API and calling it then they stuff\nall that in into more the developer\nprompt which is not shown here and\nthat's adds all the context of let's say\nworking with perplexity there's certain\nways of how you handle rack questions as\nopposed to working with bold is very\ndifferent right and then I don't think\nparhelp has a user prompt because their\nproduct is not consumed directly by an\nend user but a end user prompt could be\nmore like replet or a zero right where\nusers need to type is like generate me a\nsite that that has these buttons this\nand that that goes all in the user\nprompt. So that's sort of the\narchitecture that's sort of emerging.\nAnd to your point about avoiding\nbecoming a consulting company, I think\num there's so many startup opportunities\nand building the tooling around all of\nthis stuff like for example like um\nanyone who's done prompt engineering\nknows that the examples and worked\nexamples are really important to\nimproving the quality of the output. And\nso then if you take like power as an\nexample, they really want good worked\nexamples that are specific to each\ncompany. And so you can imagine that as\nthey scale, you almost want that done\nautomatically. Like in your dream world,\nwhat you want is just like a an agent\nitself that can pluck out the best\nexamples from like the customer data set\nand then software that just like ingests\nthat straight into like wherever it\nshould belong in the pipeline without\nyou having to manually go out and plug\nthat all and ingest it in all of\nyourself. That's probably a great segue\ninto metaparrompting which is one of the\nthings we want to talk about because\nthat's that's a consistent theme that\nkeeps coming up when we talk to our AI\nstartups. Yeah, Tropier is uh one of the\nstartups I'm working with in the current\nYC batch and they've really helped\npeople like YC company Ducky do really\nin-depth understanding and debugging of\nthe prompts and the return values from a\nmulti-stage workflow. And one of the\nthings they figured out is prompt\nfolding. So you know basically one\nprompt can dynamically generate better\nversions of itself. So a good example of\nthat is a classifier prompt that\ngenerates a specialized prompt based on\nthe previous query. And so you can\nactually go in take uh the existing\nprompt that you have and actually feed\nit more examples where maybe the prompt\nfailed or didn't quite do what you\nwanted and you can actually instead of\nyou having to go and rewrite the prompt,\nyou just put it into um you know the raw\nLLM and say help me make this prompt\nbetter. And because it knows itself so\nwell, strangely um metaprompting is\nturning out to be a very very powerful\ntool that everyone's using now. And the\nnext step after uh you do sort of prompt\nfolding if the task is very complex\nthere's this concept of uh using\nexamples and this is what Jasberry does\nis one of the companies I'm working with\nthis batch they basically build\nautomatic bug finding in code which is a\nlot harder and the way they do it is\nthey feed a bunch of really hard\nexamples that only expert programmers\ncould do let's say if you want to find\nan N plus1 query it's actually hard for\ntoday for even like the best LMS to find\nthose and the way to do those is they\nfind parts of the code then they add\nthose into the prompt a meta prompt\nthat's like hey this is an example of n\nplus1 type of error and then that works\nit out and I think this pattern of\nsometimes when it's too hard to even\nkind of write a pros around it let's\njust give you an example that turns out\nto work really well because it helps LM\nto reason around complicated tasks and\nsteer it better because you can't quite\nkind of put exact act parameters and\nit's almost like um unit testing\nprogramming in a sense like test-driven\ndevelopment is sort of the LLM v version\nof that. Yeah. Another thing that trope\nuh sort of talks about is you know the\nthe model really wants to actually help\nyou so much that if you just tell it\ngive me back output in this particular\nformat even if it doesn't quite have the\ninformation it needs it'll actually just\ntell you what it thinks you want to hear\nand it's literally a hallucination. So,\none thing they discovered is that you\nactually have to give the LLM's a real\nescape hatch. You need to tell it if you\ndo not have enough information to say\nyes or no or make a determination, don't\njust make it up. Stop and ask me. And\nthat's a very different way to think\nabout it. That's actually something we\nlearned at some of the internal work\nthat we've done with agents at YC where\nJared came up with a really inventive\nway to give the LLM escape patch. Did\nyou want to talk about that? Yeah. So\nthe trope approach is one way to give\nthe LM an escape patch. We came up with\na different way which is in the response\nformat to give it the ability to have\npart of the response be essentially a\ncomplaint to you the developer that like\nyou have given it confusing or\nunderspecified information and it\ndoesn't know what to do. And then the\nnice thing about that is that we just\nrun your LLM like in production with\nreal hoser data and then you can go back\nand you can look at the outputs that it\nhas given you in that like output\nparameter. Um we we call it debug info\ninternally. So like we have this like\ndebug info parameter where it's\nbasically reporting to us things that we\nneed to fix about it and it literally\nends up being like a to-do list that you\nthe agent developer has to do. It's like\nreally kind of mind-blowing stuff. Yeah.\nYeah, I mean just even for hobbyists or\npeople who are interested in playing\naround for this for personal projects.\nLike a very simple way to get started\nwith meta prompting is to follow the\nsame structure of the prompt is give it\na role and make the role be like you\nknow you're a expert prompt engineer who\ngives really like detailed um great\ncritiques and advice on how to um\nimprove prompts and give it the prompt\nthat you had in mind and it will spit\nyou back a much a more expanded better\nprompt and so you can just keep running\nthat loop for a while. Works\nsurprisingly well. I think it's a common\npattern sometimes for companies when\nthey need to get um responses from\nelement elements in their product a lot\nquicker. They do the meta prompting with\na bigger beefier model any of the I\ndon't know hundreds of billions of\nparameter plus models like uh I guess\ncloud 4 3.7 or your uh GPD 03 and they\ndo this meta prompting and then they\nhave a very good working one that then\nthey use into the distilled model. So\nthey use it on uh for example an FRO and\nit ends up working pretty well\nspecifically sometimes for uh voice AI\nagents companies because uh latency is\nvery important to uh get this whole\ntouring test to pass because if you have\ntoo much pause be before the agent\nresponds I think humans can detect\nsomething is off. So they use a faster\nmodel but with a bigger better prompt\nthat was refined from the bigger models.\nSo that's like a common pattern as well.\nAnother again less sophisticated maybe\nbut um like as the prompt gets longer\nand longer like it becomes a a large\nworking doc um one thing I found useful\nis as you're using it if you just note\ndown in a Google doc things that you're\nseeing just um the outputs not being how\nyou want or not ways that you can think\nof to improve it. you can just write\nthose in note form and then give Gemini\nPro like your notes plus the original\nprompt and ask it to suggest a bunch of\nedits to the prompt um to incorporate\nthese in well and it does that quite\nwell. The other trick is uh in uh Gemini\n2.5 Pro if you look at the thinking\ntraces as is uh parsing through uh\nevaluation you could actually learn a\nlot about all those misses as well.\nWe've done that internal as well, right?\nAs this is critical because if you're\njust using Gemini via the API until\nrecently, you did not get the thinking\ntraces and like the thinking traces are\nlike the critical debug information to\nlike understand like what's wrong with\nyour prompt. They just added it to the\nAPI. So you can now actually like pipe\nthat back into your developer tools and\nworkflows. Yeah, I think it's an\nunderrated um consequence of Gemini Pro\nhaving such long context windows is you\ncan effectively use it like a a ripple.\nGo sort of like one by one like put your\nprompt on like one example then\nliterally watch the reasoning trace in\nreal time to figure out like how you can\nsteer it in the direction you want.\nJared and the software team at YC has\nactually built this um you know various\nforms of workbenches that allow us to\nlike do debug and things like that. But\nto your point like sometimes it's better\njust to use\ngemini.google.com directly and then drag\nand drop you know literally JSON files\nand uh you know you don't have to do it\nin some sort of special container like\nit you know seems to be totally\nsomething that works even directly in\nyou know chat GPT itself. Yeah, this is\nall stuff. Um, I would give a shout out\nto YC's head of data, Eric Bacon, who's\num, helped us all a lot a lot of this\nmetaparrotting and using Gemini Pro 2.5\nas a effectively a ripple. What about\nevals? I mean, we've uh, talked about\nevals for going on a year now. Um, what\nare some of the things that founders are\ndiscovering? Even though we've been\nsaying this for a year or more now,\nGary, I think it's still the case that\nlike evals are the true crown jewel like\ndata asset for all of these companies.\nLike one one reason that Powerhel was\nwilling to open source the prompt is\nthey told me that they actually don't\nconsider the prompts to be the crown\njewels like the evals are the crown\njewels because without the evals you\ndon't know why the prompt was written\nthe way that it was. Um and it's very\nhard to improve it. Yeah. And I I think\nin abstraction you can think about you\nknow YC funds a lot of companies\nespecially in vertical AI and SAS and\nthen you can't get the eval unless you\nsitting literally side by side with\npeople who are doing X Y or Z knowledge\nwork. you know, you need to sit next to\nthe tractor sales regional manager and\nunderstand, well, you know, this person\ncares, you know, this is how they get\npromoted. This is what they care about.\nThis is that person's reward function.\nAnd then you know what you're doing is\ntaking these in-person interactions\nsitting next to someone in Nebraska and\nthen going back to your computer and\ncodifying it into uh very specific evals\nlike this particular user wants this\noutcome after they you know after this\ninvoice comes in we have to decide\nwhether we're going to honor the you the\nwarranty on this tractor. Like just to\ntake one of one example that's the true\nvalue right like you everyone's really\nworried about um are we just rappers and\nyou know what is going to happen to\nstartups and I think this is literally\nwhere the rubber meets the road where um\nif you you know if you are out there in\nparticular places understanding that\nuser better than anyone else and having\nthe software actually work for those\npeople that's the moat is that is like\nsuch a perfect depiction of like what is\nthe core competency required of founders\ntoday? Like literally like the thing\nthat you just said like that's your job\nas a founder of a company like this is\nto be really good at that thing and like\nmaniacally obsessed with like the\ndetails of the regional tractor sales\nmanager workflow. Yeah. And then the\nwild thing is it's very hard to do like\nyou know how you have you even been to\nNebraska you know the classic view is\nthat uh the best founders in the world\nthey're you know sort of really great\ncracked engineers and technologists and\nuh just really brilliant and then at the\nsame time they have to understand some\npart of the world that very few people\nunderstand and then there's this little\nsliver that is you know uh the founder\nof a multi-billion dollar startup you\nknow I think of Ryan Peterson from\nFlexport, you know, really really great\nperson who understands how software is\nbuilt, but then also I think he was the\nthird biggest uh importer of medical hot\ntubs for an entire year like you know a\ndecade ago. So you know the weirder that\nis the more of the world that you've\nseen that nobody else who's a\ntechnologist has seen uh the greater the\nopportunity actually. I think you've put\nthis in a really interesting way before\nGary where you're sort of saying that\nevery founder's become a forward\ndeployed engineer. That's like a term\nthat traces back to Palunteer and since\nyou were early at Palanteer maybe tell\nus a little bit about how did forward\ndeployed engineer become a thing at\nPalunteer and and what can founders\nlearn from it now? I mean I think the\nwhole thesis of Palunteer at some level\nwas that um if you look at Meta back\nthen it was called Facebook or Google or\nany of the top software startups that\neveryone sort of knew back then. One of\nthe key recognitions that Peter Teal and\nAlex Karp and Stefan Cohen and Joe\nLansdale, Nathan Gettings, like the\noriginal founders of Palunteer had was\nthat uh go into anywhere in the Fortune\n500, go into any government agency in\nthe world, including the United States,\nand nobody who understands computer\nscience and technology at the level that\nyou at the highest possible level would\never even be in that room. And so\nPalenteer's sort of really really big\nidea that they discovered very early was\nthat uh the problems that those places\nface they're actually multi-billion\ndollar sometimes trillion dollar\nproblems and yet uh this was well before\nAI became a thing you know I mean people\nwere sort of talking about machine\nlearning but you know back then they\ncalled it data mining you know the world\nis a wash in data these you know giant\ndatabases of people and things and\ntransactions and we have no idea what to\ndo with it. That's what Palanteer was,\nis and still is. That um you can go and\nfind the world's best technologists who\nknow how to write software to actually\nmake sense of the world. You know, you\nhave these pabytes of data and you don't\nknow how do you find the needle in the\nhaststack. Um and you know the wild\nthing is going on uh something like 20\n22 years later it's only become more\ntrue that we have more and more data and\nwe have less and less of an\nunderstanding of what's going on and uh\nit's no mistake that actually now that\nwe have LLMs like we actually it is\nbecoming much more tractable and then\nthe forward deployed engineer title was\nspecifically how do you sit next to\nliterally the FBI agent who's um\ninvestigating domestic terrorism. How do\nyou sit right next to them in their\nactual office and see what does the case\ncoming in look like? What are all the\nsteps? Uh when you actually need to go\nto the federal prosecutor, what are the\nthings that they're sending? Is it I\nmean what's funny is like literally it's\nlike word documents and Excel\nspreadsheets, right? And um what you do\nas a forward deployed engineer is take\nthese sort of you know file cabinet and\nfax machine things that people have to\ndo and then convert it into really clean\nsoftware. So you know the classic view\nis that it should be as easy to actually\ndo uh an investigation at a threeletter\nagency as going and taking a photo of\nyour lunch on Instagram and posting it\nto all your friends. Like that's you\nknow kind of the funniest part of it.\nAnd so you I think it's no mistake today\nthat four deployed engineers who came up\nthrough that system at Palanteer now\nthey're turning out to be some of the\nbest founders at YC actually. Yeah. I\nmean produced this incredible an\nincredible number of startup founders\ncuz yeah like the training to be a fore\ndeployed engineer that's exactly the\nright training to be a founder of these\ncompanies. Now the the other interesting\nthing about Palunteer is like other\ncompanies would send like a salesperson\nto go and sit with the FBI agent and\nlike Palunteer sent engineers to go and\ndo that. I think Palenter was probably\nthe first company to really like\ninstitutionalize that and scale that as\na process, right? Yeah. I mean, I think\nwhat happened there, the reason why they\nwere able to get these sort of seven and\neight and now nine figure contracts very\nconsistently is that uh instead of\nsending someone who's like hair and\nteeth and they're in there and you know,\nlet's go to the let's go to the uh\nsteakhouse. You know, it's all like\nrelationship. and you'd have one meeting\nuh they would really like the\nsalesperson and then through sheer force\nof personality you'd try to get them to\ngive you a seven-figure contract and\nlike the time scales on this would be\nyou know 6 weeks 10 weeks 12 weeks like\n5 years I don't know it's like and the\nsoftware would never work uh whereas if\nyou put an engineer in there and you\ngive them uh you know Palunteer Foundry\nwhich is what they now call sort of\ntheir core uh data viz and data mining\nsuites instead of the next meeting being\nreviewing 50 pages of you know sort of\nsales documentation or a contract or a\nspec or anything like that. It's\nliterally like, \"Okay, we built it.\" And\nthen you're getting like real live\nfeedback within days. And I mean, that's\nhonestly the biggest opportunity for\nstartup founders. If startup founders\ncan do that and uh that's what forward\ndeployed engineers are sort of used to\ndoing that's how you could beat a\nSalesforce or an Oracle or you know a\nBooze Allen or literally any company out\nthere that has a big office and a big\nfancy you know you have big fancy\nsalespeople with big strong handshakes\nand it's like how does a really good\nengineer with a weak handshake go in\nthere and beat them? It's actually you\nshow them something that they've never\nseen before and like make them feel\nsuper heard. You have to be super\nempathetic about it. Like you actually\nhave to be a great designer and product\nperson and then you know come back and\nyou can just blow them away. Like the\nsoftware is so powerful that you know\nthe second you see something that you\nknow makes you feel seen you want to buy\nit on the spot. Is a good way of\nthinking about it that founders should\nthink about themselves as being the four\ndeployed engineers of their own company.\nAbsolutely. Yeah. Like you definitely\ncan't farm this out. Like literally the\nfounders themselves, they're technical.\nThey have to be the great product\npeople. They have to be the\nethnographer. They have to be the\ndesigner. You want the person on the\nsecond meeting to see the demo you put\ntogether based on the stuff you heard.\nAnd you want them to say, \"Wow, I've\nnever seen anything like that.\" And take\nmy money. I think the incredible thing\nabout this model is this is why we're\nseeing a lot of the vertical AI agents\ntake off is precisely this because they\ncan have these meetings with the end\nbuyer and champion at these big\nenterprises. They take that context and\nthen they stuff it basically in the\nprompt and then they can quickly come\nback in a meeting like just the next day\nmaybe with Palunteer would have taken a\nbit longer and a team of engineers here.\nIt could be just the two founders go in\nand then they would close this six,\nseven figure deals which we've seen and\nwith large enterprises which has never\nbeen done before and it's just possible\nwith this new model of forward deploy\nengineer plus AI is just on\naccelerating. It just reminds me of a\ncompany I mentioned before on the\npodcast like Giger ML who do customer\nanother customer support and especially\na lot of voice support and it's just\nclassic case of two extremely um\ntalented software engineers not natural\nsales people but they force themselves\nto be essentially forward deployed\nengineers and they closed a huge deal\nwith Zeppto and then a couple of other\ncompanies they can't announce yet but do\nthey physically go on site like the\npalentier model? Yes. So they did so\nthey they did all of that where once\nthey close the deal they go on site and\nthey sit there with all the customer\nsupport people and figuring out how to\nkeep tuning and getting the software or\nthe LM to work even better. But before\nthat even to win the deal what they\nfound is that they can they can win by\njust having the most impressive demo.\nAnd in their case they've um innovated a\nbit on the rag pipeline so that they can\num have their voice responses be both\naccurate and very low latency. sort of\nlike a technically challenging thing to\ndo, but I just feel like in the like pre\nsort of the current LLM rise, you\ncouldn't necessarily differentiate\nenough in the demo phase of sales to\nbeat out incumbent. So, you can really\nbeat Salesforce by having a slightly\nbetter CRM with a better UI. But now\nbecause the technology evolves so fast\nand it's so hard to get this like last\nfive 10 five to 10% correct, you can\nactually if you're a forward deployed\nengineer go in do the first meeting\ntweak it so that it works really well\nfor that customer. Go back with the demo\nand just get that oh wow like we've not\nseen anyone else pull this off before\nexperience and close huge deals. And\nthat was the exact same case with Happy\nRobot who has sold seven figure\ncontracts to the top three largest\nlogistic brokers in the world. They\nbuild AI voice agents for that. They are\nthe ones doing the forward deploy\nengineer model and talking to like the\nCIOS of these companies and quickly\nshipping a lot of product like very very\nquick turnaround. And it's been\nincredible to see that take off right\nnow. And it started from six figure\ndeals now doing closing and seven figure\ndeals which is crazy. This is just a\ncouple months after. So that's the kind\nof stuff that you can do with uh I mean\nunbelievably very very smart prompt\nengineering actually. Well, one of the\nthings that's kind of interesting about\nuh each model is that they each seem to\nhave their own personality. And one of\nthe things the founders are really\nrealizing is that you're going to go to\ndifferent people for different things.\nActually, one of the things that's known\na lot is Claude is sort of the more\nhappy and more human steerable model.\nAnd the uh other one is Lama 4 is one\nthat needs a lot more steering. It's\nalmost like talking to a developer and\npart of it could be an artifact of not\nhaving done as much RL RHF on top of it.\nSo is a bit more rough to work with, but\nyou could actually steer it very well if\nyou\nactually are good at actually doing a\nlot of prompting and almost doing a bit\nmore RLHF, but it's a bit harder to work\nwith actually. Well, one of the things\nwe've been using uh LLMs for internally\nis actually helping founders figure out\nwho they should take money from. And so\nin that case, sometimes you need a very\nstraightforward rubric, a zero to 100.\nzero being never ever take their money\nand 100 being take their money right\naway. Like they actually help you so\nmuch that you'd be crazy not to take\ntheir money. Harj, we've been working on\nuh some scoring rubrics around that\nusing prompts. What What are some of the\nthings we've learned? So, it's certainly\nbest practice to give um LLM's rubrics,\nespecially if you want to get a\nnumerical score as the output. You want\nto give it a rubric to help it\nunderstand like how should I think\nthrough and what's like a 80 versus a\n90. But these rubrics are never perfect.\nthere's often always exceptions and you\ntried it with uh 03 versus Gemini 2.5\nand you found this this is what we found\nreally interesting is that um you can\ngive the same rubric to two different\nmodels and in our in our specific case\nwhat we found is that um 03 was very\nrigid actually like it really sticks to\nthe rubric it's heavily penalizes for\nanything that doesn't fit like the\nrubric that you've given it whereas\nGemini 2.5 Pro was actually quite good\nat being flexible in that it would apply\nthe rubric but it could also sort of\nalmost reason through why someone might\nbe like an exception or why you might\nwant to um push something up more\npositively or negatively than the rubric\nmight suggest, which I just thought was\nreally interesting cuz that it's just\nlike when you're training a person,\nyou're trying to you give them a rubric\nlike you want them to use a rubric as a\nguide, but there are always these sort\nof edge cases where you need to sort of\nthink a little bit more deeply. Um, and\nI just thought it was interesting that\nthe models themselves will handle that\ndifferently, which means they sort of\nhave different personalities, right?\nLike 03 felt a little bit more like the\nsoldier sort of like, okay, I'm\ndefinitely like check, check, check,\ncheck, check. Um, and Gemini Pro 2.5\nfelt a little bit more like a a high\nagency sort of employee was like, \"Oh,\nokay. I think this makes sense, but this\nmight be an exception in this case,\"\nwhich was um just really interesting to\nsee. Yeah, it's funny to see that for\ninvestors. You know, sometimes you have\ninvestors like a Benchmark or a Thrive,\nit's like, \"Yeah, take their money right\naway. Their process is immaculate. They\nnever ghost anyone. They answer their\nemails faster than most founders. It's,\nyou know, very impressive. And then, uh,\none example here might be, you know,\nthere are plenty of investors who are\njust overwhelmed and maybe they're just\nnot that good at managing their time.\nAnd so, they might be really great\ninvestors and their track record bears\nthat out, but they're sort of slow to\nget back. They seem overwhelmed all the\ntime. They accidentally, probably not\nintentionally ghost people. And so this\nis legitimately exactly what an LLM is\nfor. Like the debug info on some of\nthese are very interesting to see like\nyou know maybe it's a 91 instead of like\nan 89. We'll see. I guess one of the\nthings that's been really surprising to\nme as you know we ourselves are playing\nwith it and we spend you know maybe 80\nto 90% of our time with founders who are\nall the way out on the edge is uh you\nknow on the one hand the analogies I\nthink even we use to discuss this is uh\nit's kind of like coding. It kind of\nactually feels like coding in, you know,\n1995. Like the tools are not all the way\nthere. There's a lot of stuff that's\nunspecified. We're, you know, in this\nnew frontier. But personally, it also\nkind of feels like learning how to\nmanage a person where it's like, how do\nI actually communicate uh, you know, the\nthings that they need to know in order\nto make a good decision? And how do I\nmake sure that they know um, you know,\nhow I'm going to evaluate and score\nthem? And uh not only that, like there's\nthis aspect of Kaizen, you know, this um\nthis manufacturing technique that\ncreated really really good cars for\nJapan in the '90s. Uh and that principle\nactually says that the people who are\nthe absolute best at improving the\nprocess are the people actually doing\nit. That's literally why uh Japanese\ncars got so good in the '90s. And that's\nmetaprompting to me. So, I don't know.\nIt's a brave new world. We're sort of in\nthis new moment. So, with that, we're\nout of time. But can't wait to see what\nkind of prompts you guys come up with.\nAnd we'll see you next time.\n[Music]", "language": "en-US", "title": "State-Of-The-Art Prompting For AI Agents"}